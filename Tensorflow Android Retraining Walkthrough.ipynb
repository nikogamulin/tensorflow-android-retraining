{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of previously processed images: 93\n",
      "Number of images to process: 284\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "from PIL import Image\n",
    "from resizeimage import resizeimage\n",
    "import numpy\n",
    "import pywt\n",
    "import sys\n",
    "import re\n",
    "from random import shuffle\n",
    "\n",
    "FOLDER_LOG = \"log\"\n",
    "FOLDER_IMAGES = \"images\"\n",
    "FOLDER_IMAGES_SOURCE = \"images/source\"\n",
    "PROCESSED_IMAGES_FOLDER = \"images/processed\"\n",
    "FOLDER_GRAPH = \"graph\"\n",
    "\n",
    "PROCESSED_IMAGES_FILE = os.path.join(FOLDER_LOG, \"processed_images.txt\")\n",
    "SKIPPED_IMAGES_FILE = os.path.join(FOLDER_LOG, \"skipped_images.txt\")\n",
    "\n",
    "PERFORM_BLUR_ANALYSIS = False\n",
    "#settings for blurred images processing\n",
    "thresh = 35\n",
    "MinZero = 0.05\n",
    "\n",
    "#get source images folders (skip hidden)\n",
    "folders_to_check = [folder for folder in os.listdir(FOLDER_IMAGES_SOURCE) if folder[0] != '.'] \n",
    "\n",
    "if not os.path.exists(FOLDER_LOG):\n",
    "        os.makedirs(FOLDER_LOG)\n",
    "\n",
    "skipped_images_count = 0\n",
    "unprocessed_images = []\n",
    "processed_images = []\n",
    "skipped_images = []\n",
    "if os.path.exists(PROCESSED_IMAGES_FILE):\n",
    "    with open(PROCESSED_IMAGES_FILE) as f:\n",
    "        processed_images = [line.replace(\"\\n\", \"\") for line in f.readlines()]\n",
    "\n",
    "if os.path.exists(SKIPPED_IMAGES_FILE):\n",
    "    with open(SKIPPED_IMAGES_FILE) as f:\n",
    "        skipped_images = [line.replace(\"\\n\", \"\") for line in f.readlines()]\n",
    "        \n",
    "processed_images += skipped_images\n",
    "    \n",
    "for folder in folders_to_check:\n",
    "    for f in os.listdir(os.path.join(FOLDER_IMAGES_SOURCE, folder)):\n",
    "        if os.path.splitext(f)[1].lower() in ('.jpg', '.jpeg'):\n",
    "            file_path = os.path.join(folder, f)\n",
    "            if not file_path in processed_images:\n",
    "                unprocessed_images.append(os.path.join(FOLDER_IMAGES_SOURCE, file_path))\n",
    "    target_folder = os.path.join(PROCESSED_IMAGES_FOLDER, folder)\n",
    "    if not os.path.exists(target_folder):\n",
    "        os.makedirs(target_folder)\n",
    "print(\"Number of previously processed images: %d\" % len(processed_images))\n",
    "print(\"Number of images to process: %d\" % len(unprocessed_images))\n",
    "\n",
    "#shuffle list\n",
    "shuffle(unprocessed_images)\n",
    "\n",
    "unprocessed_images_count = 0\n",
    "processed_images_count = 0\n",
    "for image_path in unprocessed_images:\n",
    "    img=Image.open(image_path)\n",
    "    max_dim = img.size.index(max(img.size))\n",
    "    if max(img.size) < 320:\n",
    "        continue\n",
    "    try:\n",
    "        if max_dim == 0:\n",
    "            img = resizeimage.resize_width(img, 320)\n",
    "        else:\n",
    "            img = resizeimage.resize_height(img, 320)\n",
    "    except:\n",
    "        continue\n",
    "    \"\"\" This is an implementation of the paper found here: http://www.cs.cmu.edu/~htong/pdf/ICME04_tong.pdf \"\"\"\n",
    "    if PERFORM_BLUR_ANALYSIS:\n",
    "        im = img.convert('F')\n",
    "        x=numpy.asarray(im)\n",
    "        x_cropped=x[0:(numpy.shape(x)[0]/16)*16 - 1,0:(numpy.shape(x)[1]/16)*16 - 1]\n",
    "        LL1,(LH1,HL1,HH1)=pywt.dwt2(x_cropped,'haar')\n",
    "        LL2,(LH2,HL2,HH2)=pywt.dwt2(LL1      ,'haar')\n",
    "        LL3,(LH3,HL3,HH3)=pywt.dwt2(LL2      ,'haar')\n",
    "        Emap1=numpy.square(LH1) + numpy.square(HL1) + numpy.square(HH1)\n",
    "        Emap2=numpy.square(LH2) + numpy.square(HL2) + numpy.square(HH2)\n",
    "        Emap3=numpy.square(LH3) + numpy.square(HL3) + numpy.square(HH3)\n",
    "\n",
    "        dimx=numpy.shape(Emap1)[0]/8\n",
    "        dimy=numpy.shape(Emap1)[1]/8\n",
    "        Emax1=[]\n",
    "        vert=1\n",
    "        for j in range(0,dimx - 2):\n",
    "            horz=1;\n",
    "            Emax1.append([])\n",
    "            for k in range(0,dimy - 2):\n",
    "                Emax1[j].append(numpy.max(numpy.max(Emap1[vert:vert+7,horz:horz+7])))\n",
    "                horz=horz+8\n",
    "            vert=vert+8\n",
    "\n",
    "        dimx=numpy.shape(Emap2)[0]/4\n",
    "        dimy=numpy.shape(Emap2)[1]/4\n",
    "        Emax2=[]\n",
    "        vert=1\n",
    "        for j in range(0,dimx - 2):\n",
    "            horz=1;\n",
    "            Emax2.append([])\n",
    "            for k in range(0,dimy - 2):\n",
    "                Emax2[j].append(numpy.max(numpy.max(Emap2[vert:vert+3,horz:horz+3])))\n",
    "                horz=horz+4\n",
    "            vert=vert+4\n",
    "\n",
    "        dimx=numpy.shape(Emap3)[0]/2\n",
    "        dimy=numpy.shape(Emap3)[1]/2\n",
    "        Emax3=[]\n",
    "        vert=1\n",
    "        for j in range(0,dimx - 2):\n",
    "            horz=1;\n",
    "            Emax3.append([])\n",
    "            for k in range(0,dimy - 2):\n",
    "                Emax3[j].append(numpy.max(numpy.max(Emap3[vert:vert+1,horz:horz+1])))\n",
    "                horz=horz+2\n",
    "            vert=vert+2\n",
    "\n",
    "        N_edge=0\n",
    "        N_da=0\n",
    "        N_rg=0\n",
    "        N_brg=0\n",
    "\n",
    "        EdgeMap = []\n",
    "        for j in range(0, dimx - 2):\n",
    "            EdgeMap.append([])\n",
    "            for k in range(0, dimy - 2):\n",
    "                if (Emax1[j][k]>thresh) or (Emax2[j][k]>thresh) or (Emax3[j][k]>thresh):\n",
    "                    EdgeMap[j].append(1)\n",
    "                    N_edge = N_edge + 1\n",
    "                    rg = 0\n",
    "                    if (Emax1[j][k]>Emax2[j][k]) and (Emax2[j][k]>Emax3[j][k]):\n",
    "                        N_da=N_da+1\n",
    "                    elif (Emax1[j][k]<Emax2[j][k]) and (Emax2[j][k]<Emax3[j][k]):\n",
    "                        rg = 1\n",
    "                        N_rg=N_rg+1\n",
    "                    elif (Emax2[j][k]>Emax1[j][k]) and (Emax2[j][k]>Emax3[j][k]):\n",
    "                        rg = 1\n",
    "                        N_rg=N_rg+1\n",
    "                    if rg and (Emax1[j][k]<thresh):\n",
    "                        N_brg=N_brg+1\n",
    "                else:\n",
    "                    EdgeMap[j].append(0)\n",
    "\n",
    "        per=float(N_da)/N_edge\n",
    "        BlurExtent=float(N_brg)/N_rg\n",
    "\n",
    "    else:\n",
    "        BlurExtent = 0\n",
    "    if BlurExtent < 0.5:\n",
    "        subfolder_path_indices = [m.start() for m in re.finditer('/', image_path)]\n",
    "        if len(subfolder_path_indices) > 1:\n",
    "            subfolder_path_index = subfolder_path_indices[-2]\n",
    "        else:\n",
    "            subfolder_path_index = 0\n",
    "            \n",
    "        target_path = PROCESSED_IMAGES_FOLDER + image_path[subfolder_path_index:]\n",
    "        img.save(target_path , img.format)\n",
    "        with open(PROCESSED_IMAGES_FILE, \"a\") as myfile:\n",
    "            myfile.write(image_path[subfolder_path_index+1:] + \"\\n\")\n",
    "        processed_images_count += 1\n",
    "    else:\n",
    "        with open(SKIPPED_IMAGES_FILE, \"a\") as myfile:\n",
    "            myfile.write(image_path[subfolder_path_index+1:] + \"\\n\")\n",
    "        skipped_images_count += 1\n",
    "    total_images_count = processed_images_count + skipped_images_count\n",
    "    if (total_images_count) % 10 == 0:\n",
    "        print(\"processed %d/%d images...\" % (total_images_count, len(unprocessed_images)))\n",
    "        \n",
    "print \"Analyzed %d images: %d used, %d skipped.\" % (processed_images_count + skipped_images_count, \n",
    "                                                   processed_images_count, skipped_images_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph names settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "PROCESSED_IMAGES_ABSOLUTE_PATH = os.path.join(current_dir, PROCESSED_IMAGES_FOLDER)\n",
    "GRAPH_ABSOLUTE_PATH = os.path.join(current_dir, FOLDER_GRAPH)\n",
    "RETRAINED_GRAPH_NAME = \"inception_v3_retrained.pb\"\n",
    "OPTIMIZE_FOR_INFERENCE_GRAPH_NAME = \"inception_v3_optimized.pb\"\n",
    "GRAPH_RETRAINED_ABSOLUTE_PATH = os.path.join(GRAPH_ABSOLUTE_PATH, RETRAINED_GRAPH_NAME)\n",
    "GRAPH_OPTIMIZE_FOR_INTERFERENCE_ABSOLUTE_PATH = os.path.join(GRAPH_ABSOLUTE_PATH, OPTIMIZE_FOR_INFERENCE_GRAPH_NAME)\n",
    "LABELS = os.path.join(GRAPH_ABSOLUTE_PATH, \"labels.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to generate retraining command which can be pasted directly into console (TensorFlow root directory) to run retraining as described in [Inception retraining tutorial](https://www.tensorflow.org/versions/r0.9/how_tos/image_retraining/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bazel build -c opt --copt=-mavx tensorflow/examples/image_retraining:retrain\n",
      "bazel-bin/tensorflow/examples/image_retraining/retrain \\\n",
      " --image_dir /Users/nikogamulin/workspace/tensorflow-retraining/images/processed \\\n",
      " --model_dir /Users/nikogamulin/workspace/tensorflow-retraining/graph \\\n",
      " --output_graph /Users/nikogamulin/workspace/tensorflow-retraining/graph/inception_v3_retrained.pb --output_labels /Users/nikogamulin/workspace/tensorflow-retraining/graph/labels.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"bazel build -c opt --copt=-mavx tensorflow/examples/image_retraining:retrain\")\n",
    "print(\"\"\"bazel-bin/tensorflow/examples/image_retraining/retrain \\\\\\n --image_dir %s \\\\\\n --model_dir %s \\\\\\n --output_graph %s --output_labels %s\"\"\" % (PROCESSED_IMAGES_ABSOLUTE_PATH,\n",
    "     GRAPH_ABSOLUTE_PATH, GRAPH_RETRAINED_ABSOLUTE_PATH, LABELS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize graph for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bazel build //tensorflow/python/tools:optimize_for_inference\n",
      "bazel-bin/tensorflow/python/tools/optimize_for_inference \\\n",
      " --input /Users/nikogamulin/workspace/tensorflow-retraining/graph/inception_v3_retrained.pb \\\n",
      " --output /Users/nikogamulin/workspace/tensorflow-retraining/graph/inception_v3_optimized.pb --input_names=Mul \\\n",
      " --output_names=final_result\n"
     ]
    }
   ],
   "source": [
    "print(\"bazel build //tensorflow/python/tools:optimize_for_inference\")\n",
    "print(\"\"\"bazel-bin/tensorflow/python/tools/optimize_for_inference \\\\\\n --input %s \\\\\\n --output %s --input_names=Mul \\\\\\n --output_names=final_result\"\"\" % (GRAPH_RETRAINED_ABSOLUTE_PATH,\n",
    "     GRAPH_OPTIMIZE_FOR_INTERFERENCE_ABSOLUTE_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy graph to Andoid example folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ANDROID_EXAMPLE_FOLDER = \"/Users/nikogamulin/workspace/tensorflow/tensorflow/examples/android/assets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paste the following commands to shell and run to copy retrained (optimized) graph to android folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp /Users/nikogamulin/workspace/tensorflow-retraining/graph/inception_v3_optimized.pb /Users/nikogamulin/workspace/tensorflow/tensorflow/examples/android/assets\n",
      "cp /Users/nikogamulin/workspace/tensorflow-retraining/graph/labels.txt /Users/nikogamulin/workspace/tensorflow/tensorflow/examples/android/assets\n"
     ]
    }
   ],
   "source": [
    "print(\"cp %s %s\" %(GRAPH_OPTIMIZE_FOR_INTERFERENCE_ABSOLUTE_PATH, ANDROID_EXAMPLE_FOLDER))\n",
    "print(\"cp %s %s\" %(LABELS, ANDROID_EXAMPLE_FOLDER))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following command to build .apk:\n",
    "\n",
    "bazel build -c opt --android_cpu=armeabi-v7a tensorflow/examples/android:tensorflow_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
